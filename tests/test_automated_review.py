from prompt_systematic_review.automated_review import review_abstract_title_categorical

def test_review_abstract_title_categorical():
    temp = review_abstract_title_categorical("align and prompt: video-and-language pre-training with entity prompts",
                                             "Video-and-language pre-training has shown promising improvements on various downstream tasks. Most previous methods capture cross-modal interactions with a standard transformer-based multimodal encoder, not fully addressing the misalignment between unimodal video and text features. Besides, learning fine-grained visual-language alignment usually requires off-the-shelf object detectors to provide object information, which is bottlenecked by the detectorâ€™s limited vocabulary and expensive computation cost. In this paper, we propose Align and Prompt: a new video-and-language pre-training framework (ALPRO), which operates on sparsely-sampled video frames and achieves more effective cross-modal alignment without explicit object detectors. First, we introduce a video-text contrastive (VTC) loss to align unimodal video-text features at the instance level, which eases the modeling of cross-modal interactions. Then, we propose a novel visually-grounded pre-training task, prompting entity modeling (PEM), which learns fine-grained alignment between visual region and text entity via an entity prompter module in a self-supervised way. Finally, we pretrain the video-and-language transformer models on large webly-source video-text pairs using the proposed VTC and PEM losses as well as two standard losses of masked language modeling (MLM) and video-text matching (VTM). The resulting pre-trained model achieves state-of-the-art performance on both text-video retrieval and videoQA, outperforming prior work by a substantial margin. Implementation and pre-trained models are available at https://github.com/salesforce/ALPRO.",
                                              "gpt-4-1106-preview")
    assert temp == {"Title": "align and prompt: video-and-language pre-training with entity prompts", "Model": "gpt-4-1106-preview", "Probability": 4, 
                   "Reasoning": "The abstract describes a pre-training framework for video-and-language tasks, focusing on cross-modal alignment and introducing a novel prompting entity modeling concept. Although the study involves 'entity prompts,' it primarily concentrates on video-text interaction rather than exploring 'hard prefix prompts' as may be suggested by prompt engineering in a language model context. The relevance to prompt engineering is secondary and indirect, mainly connected through the novel use of prompts for entity modeling within a multimodal framework, not as a comprehensive study of prompt engineering itself."}