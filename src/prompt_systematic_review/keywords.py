keywords_list = [
    ["jailbreak prompt"],
    ["prompt an llm"],
    ["prompt a large language model"],
    ["prompt injection"],
    ["prompt optimization"],
    ["prompt engineering"],
    ["few-shot learning"],
    ["few shot learning"],
    ["prompt-based methods"],
    ["prompt based methods"],
    ["prompting-based methods"],
    ["prompting based methods"],
    ["few-shot prompt", "few shot prompt"],
    ["one-shot prompt", "one shot prompt"],
    ["few-shot prompting", "few shot prompting"],
    ["one-shot prompting", "one shot prompting"],
    ["prompting techniques"],
    ["prompt engineering techniques"],
    ["llm prompting"],
    ["large language model prompting"],
    ["0-shot prompt"],
    ["0 shot prompt"],
    ["zero-shot prompt"],
    ["many-shot prompt"],
    ["zero-shot prompting"],
    ["many-shot prompting"],
    ["in-context learning"],
    ["in context learning"],
    ["transformer model prompts"],
    ["prompt-based transfer learning"],
    ["nlp prompting strategies"],
    ["llm interpretability via prompts"],
    ["curriculum learning with prompts"],
    ["feedback loops in llm prompting"],
    ["human-in-the-loop prompting"],
    ["token-efficient prompting"],
    ["multimodal prompting"],
    ["instruction prompting"],
    ["prompt templating"],
    ["prompt template"],
]